import openai
import os
from typing import Optional
import asyncio
from fastapi import HTTPException


class AIFeedbackService:
    def __init__(self):
        self.client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    async def generate_feedback(
        self,
        transcript: str,
        child_age: Optional[int] = None,
        feedback_type: str = "english_challenge",
    ) -> str:
        """çµ±åˆã•ã‚ŒãŸAIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆ"""

        if feedback_type == "english_challenge":
            return await self._generate_english_challenge_feedback(transcript, child_age)
        elif feedback_type == "general":
            return await self._generate_general_feedback(transcript)
        else:
            return await self._generate_english_challenge_feedback(transcript, child_age)

    async def _generate_english_challenge_feedback(
        self, transcript: str, child_age: Optional[int] = None
    ) -> str:
        """è‹±èªãƒãƒ£ãƒ¬ãƒ³ã‚¸ç”¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯"""

        prompt = f"""
ä»¥ä¸‹ã¯å­ã©ã‚‚ãŒå¤–å›½äººã¨è‹±èªã§è©±ãã†ã¨ã—ãŸè¨˜éŒ²ã§ã™: "{transcript}"

ã“ã®å­ã®ã€Œè‹±èªãƒãƒ£ãƒ¬ãƒ³ã‚¸ã€ã‚’ä»¥ä¸‹ã®è¦³ç‚¹ã§æ¸©ã‹ãè©•ä¾¡ã—ã¦ãã ã•ã„ï¼š

ğŸŒŸ ã€å‹‡æ°—ãƒã‚¤ãƒ³ãƒˆã€‘
- å¤–å›½äººã«è©±ã—ã‹ã‘ãŸå‹‡æ°—ï¼ˆã“ã‚Œã ã‘ã§ã‚‚ç´ æ™´ã‚‰ã—ã„ï¼ï¼‰
- è‹±èªã§ä½•ã‹ã‚’ä¼ãˆã‚ˆã†ã¨ã—ãŸæŒ‘æˆ¦å¿ƒ
- å®Œç’§ã§ãªãã¦ã‚‚è«¦ã‚ãšã«ç¶šã‘ãŸç²˜ã‚Šå¼·ã•

ğŸ’« ã€æˆé•·ã®èŠ½ã€‘
- å˜èªä¸€ã¤ã§ã‚‚è‹±èªã‚’ä½¿ãˆãŸï¼ˆå¤§ããªå‰é€²ï¼ï¼‰
- ç›¸æ‰‹ã¨ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒå°‘ã—ã§ã‚‚æˆç«‹ã—ãŸ
- æ–°ã—ã„è¡¨ç¾ã‚„å ´é¢ã«æŒ‘æˆ¦ã—ãŸ

ğŸ¯ ã€æ¬¡ã¸ã®æœŸå¾…ã€‘
- ä»Šå›ã®çµŒé¨“ãŒæ¬¡ã®æŒ‘æˆ¦ã¸ã®è‡ªä¿¡ã«ãªã‚‹
- ã€Œè‹±èªã£ã¦é€šã˜ã‚‹ã‚“ã ï¼ã€ã¨ã„ã†å®Ÿæ„Ÿ
- å¤–å›½äººã¨ã®äº¤æµã¸ã®èˆˆå‘³ãŒæ·±ã¾ã‚‹

ã€é‡è¦ã€‘å®Œç’§ãªè‹±èªã§ãªãã¦ã‚‚ã€è©±ã—ã‹ã‘ãŸå‹‡æ°—ã¨æŒ‘æˆ¦ã™ã‚‹æ°—æŒã¡ãŒæœ€ã‚‚ä¾¡å€¤ãŒã‚ã‚Šã¾ã™ã€‚
ã“ã®å­ã®é ‘å¼µã‚Šã‚’å…·ä½“çš„ã«è¤’ã‚ã€ã€Œã¾ãŸè©±ã—ã¦ã¿ãŸã„ï¼ã€ã¨æ€ãˆã‚‹ã‚ˆã†ãªåŠ±ã¾ã—ã‚’æ—¥æœ¬èªã§100æ–‡å­—ç¨‹åº¦ã§æä¾›ã—ã¦ãã ã•ã„ã€‚

ãŸã¨ãˆä¸€è¨€ã—ã‹è©±ã›ãªãã¦ã‚‚ã€ãã‚Œã¯å¤§ããªæˆåŠŸã§ã™ã€‚

ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯:
"""

        try:
            print(f"ğŸ” AIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆé–‹å§‹: transcript='{transcript}'")
            print(f"ğŸ” ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·: {len(prompt)} æ–‡å­—")
            response = await self._call_openai_api(prompt)
            feedback = response.choices[0].message.content.strip()
            print(f"âœ… AIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”ŸæˆæˆåŠŸ: feedback='{feedback}'")
            return feedback

        except Exception as e:
            print(f"âŒ AIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            print(f"âŒ ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(e).__name__}")
            import traceback

            print(f"âŒ ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯: {traceback.format_exc()}")
            return f"'{transcript}' ã¨ã¦ã‚‚ä¸Šæ‰‹ã«è©±ã›ãŸã­ï¼æ¬¡å›ã‚‚é ‘å¼µã‚ã†ï¼ğŸ˜Š"

    async def _generate_general_feedback(self, transcribed_text: str) -> str:
        """ä¸€èˆ¬çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯"""

        try:
            prompt = f"""
ã‚ãªãŸã¯å„ªã—ã„å…ˆç”Ÿã§ã™ã€‚å­ä¾›ãŒè©±ã—ãŸå†…å®¹ã‚’èã„ã¦ã€æ¸©ã‹ãåŠ±ã¾ã—ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ã—ã¦ãã ã•ã„ã€‚

å­ä¾›ãŒè©±ã—ãŸå†…å®¹ï¼š
ã€Œ{transcribed_text}ã€

ä»¥ä¸‹ã®ç‚¹ã‚’å«ã‚ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã—ã¦ãã ã•ã„ï¼š
1. è©±ã—ã¦ãã‚ŒãŸã“ã¨ã¸ã®æ„Ÿè¬
2. è‰¯ã‹ã£ãŸç‚¹ã®å…·ä½“çš„ãªè¤’ã‚è¨€è‘‰
3. æ¬¡ã«å‘ã‘ã¦ã®å„ªã—ã„åŠ±ã¾ã—

ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯200æ–‡å­—ä»¥å†…ã§ã€å­ä¾›ãŒç†è§£ã—ã‚„ã™ã„è¨€è‘‰ã§æ›¸ã„ã¦ãã ã•ã„ã€‚
"""

            response = await self._call_openai_api_with_system(
                prompt,
                system_message="ã‚ãªãŸã¯å­ä¾›ãŸã¡ã‚’åŠ±ã¾ã™å„ªã—ã„å…ˆç”Ÿã§ã™ã€‚",
                model="gpt-3.5-turbo",
                max_tokens=300,
            )

            return response.choices[0].message.content.strip()

        except Exception as e:
            raise HTTPException(status_code=500, detail=f"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")

    async def _call_openai_api(self, prompt: str):
        """OpenAI APIå‘¼ã³å‡ºã—"""
        loop = asyncio.get_event_loop()

        def _sync_call():
            return self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=150,
                temperature=0.7,
                timeout=10.0,
            )

        return await loop.run_in_executor(None, _sync_call)

    async def _call_openai_api_with_system(
        self, prompt: str, system_message: str, model: str = "gpt-4o-mini", max_tokens: int = 150, temperature: float = 0.7, # è¿½åŠ 
    ):
        """OpenAI APIå‘¼ã³å‡ºã—ï¼ˆã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä»˜ãï¼‰"""
        loop = asyncio.get_event_loop()

        def _sync_call():
          return self.client.chat.completions.create(
            model=model,
            messages=[
             {"role": "system", "content": system_message},
             {"role": "user", "content": prompt},
            ],
            max_tokens=max_tokens,
            temperature=temperature,
           timeout=10.0,
          )
        return await loop.run_in_executor(None, _sync_call)
