import asyncio
import os
from typing import Optional

import openai
from fastapi import HTTPException


class AIFeedbackService:
    def __init__(self):
        self.client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    async def generate_feedback(
        self,
        transcript: str,
        child_age: Optional[int] = None,
        feedback_type: str = "english_challenge",
    ) -> str:
        """çµ±åˆã•ã‚ŒãŸAIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆ"""
        if feedback_type == "english_challenge":
            return await self._generate_english_challenge_feedback(transcript, child_age)
        elif feedback_type == "general":
            return await self._generate_general_feedback(transcript)
        else:
            return await self._generate_english_challenge_feedback(transcript, child_age)

    async def _generate_english_challenge_feedback(
        self, transcript: str, child_age: Optional[int] = None
    ) -> str:
        """è‹±èªãƒãƒ£ãƒ¬ãƒ³ã‚¸ç”¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆJSONå‡ºåŠ›ãƒ»æ¸©ã‹ã„è©•ä¾¡è¦³ç‚¹ä»˜ãï¼‰"""
        system_message = (
            "ã‚ãªãŸã¯å­ã©ã‚‚ã‚’åŠ±ã¾ã™å„ªã—ã„è‹±èªã‚³ãƒ¼ãƒã§ã™ã€‚"
            "å‡ºåŠ›ã¯å¿…ãšæ—¥æœ¬èªã§ã€ã‚„ã•ã—ãå…·ä½“çš„ã«çŸ­ãæ›¸ãã¾ã™ã€‚"
            "æœ€çµ‚å‡ºåŠ›ã¯æŒ‡å®šã®JSONã®ã¿è¿”ã—ã¦ãã ã•ã„ã€‚"
        )
        user_prompt = f"""
ä»¥ä¸‹ã¯å­ã©ã‚‚ãŒå¤–å›½äººã¨è‹±èªã§è©±ãã†ã¨ã—ãŸè¨˜éŒ²ã§ã™: "{transcript}"

æ‰‹é †:
1) æ¨å®šè©±è€…åˆ†é›¢: ã€Œå­ã©ã‚‚ãŒè©±ã—ãŸå¯èƒ½æ€§ãŒé«˜ã„ç™ºè©±ã€ã‚’æŠ½å‡ºï¼ˆçŸ­ã„æ–‡ãƒ»è¨€ã„ç›´ã—ãƒ»ãŸã‚ã‚‰ã„ãƒ»ã‚„ã•ã—ã„èªå½™ãªã©ï¼‰
2) ã“ã®å­ã®ã€Œè‹±èªãƒãƒ£ãƒ¬ãƒ³ã‚¸ã€ã‚’ä»¥ä¸‹ã®è¦³ç‚¹ã§æ¸©ã‹ãè©•ä¾¡ï¼ˆç´„50æ–‡å­—ï¼‰:
   ğŸŒŸã€å‹‡æ°—ãƒã‚¤ãƒ³ãƒˆã€‘å¤–å›½äººã«è©±ã—ã‹ã‘ãŸå‹‡æ°—ã€è‹±èªã§ä¼ãˆã‚ˆã†ã¨ã—ãŸæŒ‘æˆ¦å¿ƒ
   ğŸ’«ã€æˆé•·ã®èŠ½ã€‘å˜èªä¸€ã¤ã§ã‚‚è‹±èªã‚’ä½¿ãˆãŸã€ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒæˆç«‹ã—ãŸ
   ğŸ¯ã€æ¬¡ã¸ã®æœŸå¾…ã€‘ã“ã®çµŒé¨“ãŒæ¬¡ã®æŒ‘æˆ¦ã¸ã®è‡ªä¿¡ã«ãªã‚‹
   ã€é‡è¦ã€‘å®Œç’§ã§ãªãã¦ã‚‚ã€è©±ã—ã‹ã‘ãŸå‹‡æ°—ã¨æŒ‘æˆ¦ã™ã‚‹æ°—æŒã¡ãŒæœ€ã‚‚ä¾¡å€¤ãŒã‚ã‚‹
3) ä¼šè©±æ–‡è„ˆã«æ²¿ã£ãŸç°¡å˜ãªè‹±èªãƒ•ãƒ¬ãƒ¼ã‚ºã‚’1ã¤ææ¡ˆã—ã€ã©ã‚“ãªå ´é¢ã§ä½¿ã†ã‹ã‚’ç°¡æ½”ã«èª¬æ˜ï¼ˆå¹´é½¢: {child_age if child_age is not None else "ä¸æ˜"}ï¼‰

å‡ºåŠ›ã¯å¿…ãšæ¬¡ã®JSONã ã‘:
{{
  "child_utterances": ["å­ã©ã‚‚ã¨æ¨å®šã—ãŸç™ºè©±1", "ç™ºè©±2"],
  "feedback_short": "ğŸŒŸğŸ’«ğŸ¯ã®è¦³ç‚¹ã‚’å«ã‚€ç´„50æ–‡å­—ã®çŸ­ã„å¿œæ´ã‚³ãƒ¡ãƒ³ãƒˆ",
  "phrase_suggestion": {{ "en": "Hello", "ja": "åˆã‚ã¦ä¼šã£ãŸäººã¸ã®æŒ¨æ‹¶" }},
  "note": "è©±è€…æ¨å®šã§è¿·ã£ãŸç‚¹ãŒã‚ã‚Œã°ç°¡æ½”ã«ã€‚ãªã‘ã‚Œã°ç©ºæ–‡å­—"
}}
"""

        try:
            response = await self._call_openai_api_with_system(
                prompt=user_prompt,
                system_message=system_message,
                model="gpt-4o-mini",
                max_tokens=400,
                temperature=0.0,
            )
            return response.choices[0].message.content.strip()
        except Exception:
            return f"ã€Œ{transcript}ã€ã«æŒ‘æˆ¦ã§ãã¦ã™ã”ã„ã‚ˆï¼å¤–å›½äººã«è©±ã—ã‹ã‘ãŸå‹‡æ°—ãŒç´ æ™´ã‚‰ã—ã„ï¼æ¬¡ã‚‚é ‘å¼µã‚ã†ï¼ğŸ˜Š"

    async def _generate_general_feedback(self, transcribed_text: str) -> str:
        """ä¸€èˆ¬çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯"""
        try:
            prompt = f"""
ã‚ãªãŸã¯å„ªã—ã„å…ˆç”Ÿã§ã™ã€‚å­ä¾›ãŒè©±ã—ãŸå†…å®¹ã‚’èã„ã¦ã€æ¸©ã‹ãåŠ±ã¾ã—ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ã—ã¦ãã ã•ã„ã€‚

å­ä¾›ãŒè©±ã—ãŸå†…å®¹ï¼š
ã€Œ{transcribed_text}ã€

ä»¥ä¸‹ã®ç‚¹ã‚’å«ã‚ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã—ã¦ãã ã•ã„ï¼š
1. è©±ã—ã¦ãã‚ŒãŸã“ã¨ã¸ã®æ„Ÿè¬
2. è‰¯ã‹ã£ãŸç‚¹ã®å…·ä½“çš„ãªè¤’ã‚è¨€è‘‰
3. æ¬¡ã«å‘ã‘ã¦ã®å„ªã—ã„åŠ±ã¾ã—

ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯200æ–‡å­—ä»¥å†…ã§ã€å­ä¾›ãŒç†è§£ã—ã‚„ã™ã„è¨€è‘‰ã§æ›¸ã„ã¦ãã ã•ã„ã€‚
"""

            response = await self._call_openai_api_with_system(
                prompt,
                system_message="ã‚ãªãŸã¯å­ä¾›ãŸã¡ã‚’åŠ±ã¾ã™å„ªã—ã„å…ˆç”Ÿã§ã™ã€‚",
                model="gpt-4o-mini",
                max_tokens=300,
            )

            return response.choices[0].message.content.strip()

        except Exception as e:
            raise HTTPException(status_code=500, detail=f"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")

    async def _call_openai_api(self, prompt: str):
        """OpenAI APIå‘¼ã³å‡ºã—"""
        loop = asyncio.get_event_loop()

        def _sync_call():
            return self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=150,
                temperature=0.7,
                timeout=30.0,
            )

        return await loop.run_in_executor(None, _sync_call)

    async def _call_openai_api_with_system(
        self,
        prompt: str,
        system_message: str,
        model: str = "gpt-4o-mini",
        max_tokens: int = 150,
        temperature: float = 0.7,
    ):
        """OpenAI APIå‘¼ã³å‡ºã—ï¼ˆã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä»˜ãï¼‰"""
        loop = asyncio.get_event_loop()

        def _sync_call():
            return self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": prompt},
                ],
                max_tokens=max_tokens,
                temperature=temperature,
                timeout=30.0,
            )

        return await loop.run_in_executor(None, _sync_call)
